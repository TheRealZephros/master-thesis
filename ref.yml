farpahc:
  type: "misc"
  title: "Faroese-FarPaHC Treebank"
  url: 
    value: "https://github.com/UniversalDependencies/UD_Faroese-FarPaHC"
    date: "2024-11-29"

oft:
  type: "misc"
  title: "Faroese-OFT Treebank"
  url: 
   value: "https://github.com/UniversalDependencies/UD_Faroese-OFT"
   date: "2024-11-29"

trond_tool:
  type: "misc"
  title: "Trond Trosterud's tools for Faroese"
  url: 
    value: "https://gtweb.uit.no/cgi-bin/smi/smi.cgi?text=%C3%81+tunguni+eru+sm%C3%A1ar+tenn.&action=analyze&lang=fao&plang=eng"
    date: "2025-02-19"

farpahc_og:
  type: "misc"
  title: "Faroese Parsed Historical Corpus (FarPaHC)"
  url: 
    value: "https://github.com/einarfs/farpahc"
    date: "2025-02-19"

ud_converter:
  type: "misc"
  title: "UDConverter"
  url: 
    value: "https://github.com/thorunna/UDConverter"
    date: "2025-02-19"

ppche:
  type: "misc"
  title: "Penn Parsed Corpora of Historical English"
  url: 
    value: "https://www.ling.upenn.edu/hist-corpora/"
    date: "2025-02-19"

fo_nlp_res:
  type: "misc"
  title: "Faroese Language Resources by FoNLP"
  url: 
    value: "https://github.com/FoNLP/faroese_language_resources"
    date: "2024-12-03"

mtd_res:
  type: "misc"
  title: "Faroese Language Resources by The Centre for Language Technology"
  url: 
    value: "https://mtd.setur.fo/en/tilfeingi/swoof/product_cat-text/"
    date: "2024-12-03"

faroe_uni_press:
  type: "misc"
  title: "Faroe University Press"
  url: 
    value: "https://ojs.setur.fo/"
    date: "2024-12-03"

giellalt:
  type: "misc"
  title: "Giellatekno Language Technology Faroese Resources"
  url: 
    value: "https://github.com/giellalt/corpus-fao/tree/main"
    date: "2024-12-03"

sprotin:
  type: "misc"
  title: "Sprotin"
  url: 
    value: "https://www.sprotin.fo/"
    date: "2024-12-03"

bendingar:
  type: "misc"
  title: "Bendingar"
  url: 
    value: "https://bendingar.fo/"
    date: "2025-02-19"

nllb:
  type: "article"
  title: "No Language Left Behind"
  author:
  - NLLB Team
  - Marta R. Costa-jussà 
  - James Cross
  - Onur Çelebi
  - Maha Elbayad
  - Kenneth Heafield
  - Kevin Heffernan
  - Elahe Kalbassi
  - Janice Lam
  - Daniel Licht
  - Jean Maillard
  - Anna Sun
  - Skyler Wang
  - Guillaume Wenzek
  - Al Youngblood
  - Bapi Akula
  - Loic Barrault
  - Gabriel Mejia Gonzalez
  - Prangthip Hansanti
  - John Hoffman
  - Semarley Jarrett
  - Kaushik Ram Sadagopan
  - Dirk Rowe
  - Shannon Spruit
  - Chau Tran
  - Pierre Andrews
  - Necip Fazil Ayan
  - Shruti Bhosale
  - Sergey Edunov
  - Angela Fan
  - Cynthia Gao
  - Vedanuj Goswami
  - Francisco Guzmán
  - Philipp Koehn
  - Alexandre Mourachko
  - Christophe Ropers
  - Safiyyah Saleem
  - Holger Schwenk
  - Jeff Wang
  url: 
    value: "https://opus.nlpl.eu/NLLB/en&fo/v1/NLLB"
    date: "2025-02-17"
  date: "2022-07-11"
  serial-number:
    arxiv: '2207.05267'
    doi: 10.48550/arXiv.2207.04672
  abstract: "Driven by the goal of eradicating language barriers on a global scale, machine translation has solidified itself as a key focus of artificial intelligence research today. However, such efforts have coalesced around a small subset of languages, leaving behind the vast majority of mostly low-resource languages. What does it take to break the 200 language barrier while ensuring safe, high quality results, all while keeping ethical considerations in mind? In No Language Left Behind, we took on this challenge by first contextualizing the need for low-resource language translation support through exploratory interviews with native speakers. Then, we created datasets and models aimed at narrowing the performance gap between low and high-resource languages. More specifically, we developed a conditional compute model based on Sparsely Gated Mixture of Experts that is trained on data obtained with novel and effective data mining techniques tailored for low-resource languages. We propose multiple architectural and training improvements to counteract overfitting while training on thousands of tasks. Critically, we evaluated the performance of over 40,000 different translation directions using a human-translated benchmark, Flores-200, and combined human evaluation with a novel toxicity benchmark covering all languages in Flores-200 to assess translation safety. Our model achieves an improvement of 44% BLEU relative to the previous state-of-the-art, laying important groundwork towards realizing a universal translation system. Finally, we open source all contributions described in this work, accessible at https://github.com/facebookresearch/fairseq/tree/nllb"
  parent:
    type: periodical
    publisher: arXiv

stanza_perf:
  type: "web"
  title: "Stanza Performance Page"
  url: 
    value: "https://stanfordnlp.github.io/stanza/performance.html"
    date: "2025-05-21"

nllb_fo_1:
  type: "misc"
  title: "NLLB - Faroese - Primary"
  url: 
    value: "https://github.com/facebookresearch/fairseq/blob/nllb/examples/nllb/modeling/scripts/flores200/lang_pairs_primary.txt"
    date: "2025-03-04"

nllb_fo_2:
  type: "misc"
  title: "NLLB - Faroese - Mined"
  url: 
    value: "https://github.com/facebookresearch/fairseq/blob/nllb/examples/nllb/modeling/scripts/flores200/lang_pairs_mine.txt"
    date: "2025-03-04"

Næs:
  type: "article"
  title: "Færøsk retskrivning - resultater fra en undersøgelse af færøske stile"
  author: "Katrin Næs"
  date: "2005"
  url:
    value: "http://ojs.statsbiblioteket.dk/index.php/sin/issue/archive"
    date: "2025-03-10"

spell_errors_src:
  type: "misc"
  title: "Spelling Errors text files"
  url: 
    value: "https://github.com/giellalt/lang-fao/tree/main/tools/spellcheckers"
    date: "2025-03-07"

bend_grunn:
  type: "misc"
  title: "Bendingarunnurin"
  url: 
    value: "https://bendingar.fo/um/"
    date: "2025-02-19"

rætt:
  type: "misc"
  title: "Rættstavarin"
  url: 
    value: "https://divvun.org/"
    date: "2025-02-19"

fo_ordabók:
  type: "book"
  title: "Føroysk Orðabók"
  author: Jóhan Hendrik W. Poulsen
  publisher: Føroya Fróðskaparfelag
  date: "1998"

Vaswani2017:
  type: article
  title: Attention Is All You Need
  author:
  - Vaswani, Ashish
  - Shazeer, Noam
  - Parmar, Niki
  - Uszkoreit, Jakob
  - Jones, Llion
  - Gomez, Aidan N.
  - Kaiser, Lukasz
  - Polosukhin, Illia
  date: 2017-06
  serial-number:
    arxiv: '1706.03762'
    doi: 10.48550/ARXIV.1706.03762
  abstract: The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.
  parent:
    type: periodical
    publisher: arXiv

Raffel2019:
  type: article
  title: "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"
  author:
  - Colin Raffel
  - Noam Shazeer
  - Adam Roberts
  - Katherine Lee
  - Sharan Narang
  - Michael Matena
  - Yanqi Zhou
  - Wei Li
  - Peter J. Liu
  date: 2019-10
  serial-number:
    arxiv: '1910.10683'
    doi: 10.48550/arXiv.1910.10683
  abstract: Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts all text-based language problems into a text-to-text format. Our systematic study compares pre-training objectives, architectures, unlabeled data sets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new ``Colossal Clean Crawled Corpus'', we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our data set, pre-trained models, and code.
  parent:
    type: periodical
    publisher: arXiv

mt5:
  type: article
  title: "mT5: A massively multilingual pre-trained text-to-text transformer"
  author:
  - Linting Xue
  - Noah Constant
  - Adam Roberts
  - Mihir Kale
  - Rami Al-Rfou
  - Aditya Siddhant
  - Aditya Barua
  - Colin Raffel
  date: 2021-05
  serial-number:
    arxiv: '2010.11934v3'
    doi: 10.48550/arXiv.2010.11934
  abstract: The recent “Text-to-Text Transfer Transformer” (T5) leveraged a unified text-to-text format and scale to attain state-of-the-art results on a wide variety of English-language NLP tasks. In this paper, we introduce mT5, a multilingual variant of T5 that was pre-trained on a new Common Crawl-based dataset covering 101 languages. We detail the design and modified training of mT5 and demonstrate its state-of-the-art performance on many multilingual benchmarks. We also describe a simple technique to prevent “accidental translation” in the zero-shot setting, where a generative model chooses to (partially) translate its prediction into the wrong language. All of the code and model checkpoints used in this work are publicly available.
  parent:
    type: periodical
    publisher: arXiv

nawrot:
  type: article
  title: "nanoT5: Fast & Simple Pre-training and Fine-tuning of T5 Models with Limited Resources"
  author: Piotr Nawrot
  date: 2023-12
  url:
    value: "https://aclanthology.org/2023.nlposs-1.11"
    date: "2025-05-12"
  serial-number:
    arxiv: '2309.02373'
    doi: 10.48550/arXiv.2309.02373
  publisher: Association for Computational Linguistics
  booktitle: "Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023)"

Brockett2006:
  type: conference
  author:
    - Chris Brockett
    - William B. Dolan
  title: "Correcting ESL Errors Using Phrasal SMT Techniques"
  container-title: "Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics"
  publisher: Association for Computational Linguistics
  issued: 2006
  page: 249-256
  url:
    value: https://aclanthology.org/P06-1032

Bryant2017:
  type: article
  author:
    - Christopher Bryant
    - Mariano Felice
    - Ted Briscoe
  title: "Automatic annotation and evaluation of error types for grammatical error correction"
  container-title: "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics"
  publisher: Association for Computational Linguistics
  issued: 2017
  page: 793-805
  url:
    value: https://aclanthology.org/P17-1073

Chodorow2010:
  type: conference
  author:
    - Martin Chodorow
    - Claudia Leacock
    - Joel R. Tetreault
  title: "Detection of Grammatical Errors Involving Prepositions"
  container-title: "NAACL HLT 2010 - The 2010 Annual Conference of the North American Chapter of the ACL"
  issued: 2010
  page: 353-358
  publisher: Association for Computational Linguistics
  url:
    value: https://aclanthology.org/N10-1052

Dahlmeier2013:
  type: article
  author:
    - Daniel Dahlmeier
    - Hwee Tou Ng
    - Siew Mei Wu
  title: "Building a Large Annotated Corpus of Learner English: The NUS Corpus of Learner English"
  container-title: "Proceedings of the Eighth Workshop on Innovative Use of NLP for Building Educational Applications"
  publisher: Association for Computational Linguistics
  issued: 2013
  page: 22-31
  url:
    value: https://aclanthology.org/W13-1703

Grundkiewicz2019:
  type: article
  author:
    - Roman Grundkiewicz
    - Marcin Junczys-Dowmunt
  title: "Neural Grammatical Error Correction Systems with Unsampled Datasets"
  container-title: "Proceedings of the 14th Workshop on Innovative Use of NLP for Building Educational Applications"
  publisher: Association for Computational Linguistics
  issued: 2019
  page: 252-263
  url:
    value: https://aclanthology.org/W19-4430

Kaneko2020:
  type: article
  author:
    - Masahiro Kaneko
    - Mamoru Komachi
  title: "Encoder-decoder models can learn syntactic and semantic phenomena in grammatical error correction"
  container-title: "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics"
  issued: 2020
  page: 7029-7035
  publisher: Association for Computational Linguistics
  url:
    value: https://aclanthology.org/2020.acl-main.628

Leacock2014:
  type: book
  author:
    - Claudia Leacock
    - Martin Chodorow
    - Michael Gamon
    - Joel Tetreault
  title: "Automated Grammatical Error Detection for Language Learners"
  publisher: Morgan & Claypool Publishers
  issued: 2014
  doi: 10.2200/S00593ED1V01Y201401HLT024

Lichtarge2019:
  type: conference
  author:
    - Jeffery Lichtarge
    - Chris Alberti
    - Daniel Andor
    - Emily Pitler
    - Z. Wei
  title: "Corpora Generation for Grammatical Error Correction"
  container-title: "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics"
  publisher: Association for Computational Linguistics
  issued: 2019
  page: 3291-3299
  url:
    value: https://aclanthology.org/N19-1332

Liu2020:
  type: article
  author:
    - Yinhan Liu
    - Jiatao Gu
    - Naman Goyal
    - Xian Li
    - Sergey Edunov
    - Marjan Ghazvininejad
    - Mike Lewis
    - Luke Zettlemoyer
  title: "Multilingual Denoising Pre-training for Neural Machine Translation"
  container-title: "Transactions of the Association for Computational Linguistics"
  issued: 2020
  page: 726-742
  url:
    value: https://aclanthology.org/2020.tacl-1.47

Mizumoto2011:
  type: conference
  author:
    - Tomoya Mizumoto
    - Mamoru Komachi
    - Masaaki Nagata
    - Yuji Matsumoto
  title: "Mining Revision Log of Language Learning SNS for Automated Japanese Error Correction of Second Language Learners"
  container-title: "Proceedings of the 5th International Joint Conference on Natural Language Processing"
  issued: 2011
  page: 147-155
  publisher: Asian Federation of NLP
  url:
    value: https://aclanthology.org/I11-1017

Ng2014:
  type: conference
  author:
    - Siew Mei Ng
    - Hwee Tou Ng
  title: "The CoNLL-2014 Shared Task on Grammatical Error Correction"
  container-title: "Proceedings of the Eighteenth Conference on Computational Natural Language Learning: Shared Task"
  publisher: Association for Computational Linguistics
  issued: 2014
  page: 1-14
  url:
    value: https://aclanthology.org/W14-1701

Omelianchuk2020:
  type: article
  author:
    - Kostiantyn Omelianchuk
    - Vitaliy Atrasevych
    - Artem Chernodub
    - Oleksandr Skurzhanskyi
  title: "GECToR - Grammatical Error Correction: Tag, Not Rewrite"
  container-title: "Proceedings of the 15th Workshop on Innovative Use of NLP for Building Educational Applications"
  publisher: Association for Computational Linguistics
  issued: 2020
  page: 163-170
  url:
    value: https://aclanthology.org/2020.bea-1.17

Rotman2022:
  type: article
  author:
    - Guy Rotman
    - Reut Tsarfaty
  title: "On the Transferability of Neural Grammatical Error Correction Models Across Languages"
  container-title: "Transactions of the Association for Computational Linguistics"
  issued: 2022
  page: 1381-1398
  url:
    value: https://aclanthology.org/2022.tacl-1.40

Rozovskaya2010:
  type: article
  author:
    - Alla Rozovskaya
    - Dan Roth
  title: "Annotating ESL Errors Using Crowdsourcing"
  container-title: "Proceedings of the NAACL HLT 2010 Fifth Workshop on Building Educational Applications Using NLP"
  issued: 2010
  page: 74-82
  publisher: Association for Computational Linguistics
  url:
    value: https://aclanthology.org/W10-1009

Xie2018:
  type: conference
  author:
    - Ziang Xie
    - Anand Avati
    - Naveen Arivazhagan
    - Dan Jurafsky
    - Andrew Ng
  title: "Noising and Denoising Natural Language: Diverse Backtranslation for Grammar Correction"
  container-title: "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics"
  issued: 2018
  page: 619-628
  publisher: Association for Computational Linguistics
  url:
    value: https://aclanthology.org/N18-1063